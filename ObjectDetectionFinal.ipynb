{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bXEi7xawIHqJ"},"outputs":[],"source":["import cv2\n","import cvlib as cv\n","from cvlib.object_detection import draw_bbox\n","import os\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","\n","!wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\"\n","!wget \"https://pjreddie.com/media/files/yolov3.weights\"\n","!wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\"\n","\n","# load the COCO class labels our YOLO model was trained on\n","labelsPath = os.path.sep.join([\"/content\",\"coco.names\"])\n","LABELS = open(labelsPath).read().strip().split(\"\\n\")\n"," \n","# initialize a list of colors to represent each possible class label\n","np.random.seed(42)\n","COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),\n","\tdtype=\"uint8\")\n","\n","# derive the paths to the YOLO weights and model configuration\n","weightsPath = os.path.sep.join([\"/content\", \"yolov3.weights\"])\n","configPath = os.path.sep.join([\"/content\", \"yolov3.cfg\"])\n","\n","# load our YOLO object detector trained on COCO dataset (80 classes)\n","print(\"[INFO] loading YOLO from disk...\")\n","detector = cv2.dnn.readNetFromDarknet('/content/yolov3.cfg', '/content/yolov3.weights')\n","#detector = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For Video\n","from google.colab.patches import cv2_imshow\n","\n","video_capture = cv2.VideoCapture(\"/content/drive/MyDrive/demo (online-video-cutter.com).mp4\")\n","\n","# determine only the *output* layer names that we need from YOLO\n","ln = detector.getLayerNames()\n","ln = [ln[i - 1] for i in detector.getUnconnectedOutLayers()]\n","\n","# video_capture = cv2.VideoCapture(0)\n","while True:\n","    # Capture frame-by-frame\n","    re,img = video_capture.read()\n","    try:\n","       img = cv2.resize(img, (1400, 1000), interpolation=cv2.INTER_AREA)\n","       print(img.shape)\n","    except:\n","        break\n","    height, width, channels = img.shape\n","\n","\n","    # USing blob function of opencv to preprocess image\n","    blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n","    #Detecting objects\n","    detector.setInput(blob)\n","    outs = detector.forward(ln)\n","\n","\n","    # Showing informations on the screen\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:\n","                # Object detected\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Rectangle coordinates\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","    \n","    #We use NMS function in opencv to perform Non-maximum Suppression\n","    #we give it score threshold and nms threshold as arguments.\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","    font = cv2.FONT_HERSHEY_PLAIN\n","    colors = np.random.uniform(0, 255, size=(len(LABELS), 3))\n","    for i in range(len(boxes)):\n","        if i in indexes:\n","            x, y, w, h = boxes[i]\n","            label = str(LABELS[class_ids[i]])\n","            color = colors[class_ids[i]]\n","            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n","            cv2.putText(img, label, (x, y + 30), font, 2, color, 3)\n","\n","    plt.imshow(img)\n","    # plt.imshow(\"Image\",cv2.resize(img, (800,600)))\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","video_capture.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Capture frame-by-frame\n","image = cv2.imread(\"/content/drive/MyDrive/ObjectTracking/images/soccer.jpg\")\n","height, width, channels = image.shape\n","plt.imshow(image)\n","\n","# image = cv2.imread(\"/content/drive/MyDrive/ObjectTracking/images/living_room.jpg\")\n","# height, width, channels = image.shape\n","# plt.imshow(image)\n","\n","# image = cv2.imread(\"/content/drive/MyDrive/ObjectTracking/images/9th-food.jpg\")\n","# height, width, channels = image.shape\n","# plt.imshow(image)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# conversion of BGR to grayscale is necessary o atpply this operation\n","img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# determine only the *output* layer names that we need from YOLO\n","ln = detector.getLayerNames()\n","ln = [ln[i - 1] for i in detector.getUnconnectedOutLayers()]\n","\n","\n","# USing blob function of opencv to preprocess image\n","blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n","#Detecting objects\n","detector.setInput(blob)\n","outs = detector.forward(ln)\n","\n","# Showing informations on the screen\n","class_ids = []\n","confidences = []\n","boxes = []\n","for out in outs:\n","    for detection in out:\n","        scores = detection[5:]\n","        class_id = np.argmax(scores)\n","        confidence = scores[class_id]\n","        if confidence > 0.5:\n","                # Object detected\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","\n","                # Rectangle coordinates\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","                class_ids.append(class_id)\n","    \n","  #  ### We use NMS function in opencv to perform Non-maximum Suppression\n","  #  ### we give it score threshold and nms threshold as arguments.\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n","    colors = np.random.uniform(0, 255, size=(len(LABELS), 3))\n","    for i in range(len(boxes)):\n","        if i in indexes:\n","            x, y, w, h = boxes[i]\n","            label = str(LABELS[class_ids[i]])\n","            color = colors[class_ids[i]]\n","            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n","            cv2.putText(img, label, (x, y -5),cv2.FONT_HERSHEY_SIMPLEX,\n","\t\t\t1/2, color, 2)\n","\n","\n","plt.imshow(img)\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Counting the number of personss\n","box, label, c_score= cv.detect_common_objects(image)\n","output= draw_bbox(image, box, label, c_score)\n","plt.show()\n","print('Number of persons in this image : ', label.count('person'))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOO+5hdOoZlrCEEmEcfJKq8","mount_file_id":"1jCsmHZRrSRv0Jqq_7heagwcBMq5T7oGX","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
